{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a5f535a1",
      "metadata": {
        "id": "a5f535a1"
      },
      "source": [
        "## Исследование эффекта гроккинга"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e1cb90a",
      "metadata": {
        "id": "4e1cb90a"
      },
      "source": [
        "За основу взята статья Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets:\n",
        "https://arxiv.org/pdf/2201.02177.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8374357",
      "metadata": {
        "id": "b8374357"
      },
      "source": [
        "## 1. Вступление"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f47e2a",
      "metadata": {
        "id": "c5f47e2a"
      },
      "source": [
        "В данной статье описывается т.н. эффект гроккинга: нейросеть резко переходит от качества случайного угадывания к идеальному качеству, причём случается это сильно после точки переобучения."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb143d5b",
      "metadata": {
        "id": "fb143d5b"
      },
      "source": [
        "Авторы данной работы наблюдают этот эффект на данных вида aob=c, где \"a\",\"b\",\"c\" - числа, а \"o\" - некая операция. Состовляется таблица, где строки и столбцы это всевозможные значения \"a\" и \"b\", в ячейках которой хранятся соответствующие этим \"a\" и \"b\" - \"c\". Далее, случайным образом стираются некоторые ячейки(то есть разбиваем выборку на train и test(пустые ячейки)). Задача состоит в том, чтобы заполнить пустые ячейки в соответствии с выше описанной операцией."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65fc93a",
      "metadata": {
        "id": "b65fc93a"
      },
      "source": [
        "В этой научной работе авторы наблюдали этот эффект на многих операциях, но мы остановимся на нескольких из них. Тип нейросети - трансформер, в качестве оптимизатора будем использовать AdamW, поскольку данный эффект наиболее отчетливо наблюдается при его использовании."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd62ee74",
      "metadata": {
        "id": "fd62ee74"
      },
      "source": [
        "## 2. Программная реализация"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40c35f29",
      "metadata": {
        "id": "40c35f29"
      },
      "source": [
        "### Библиотеки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8357a017",
      "metadata": {
        "id": "8357a017"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torch.optim import AdamW, Adam, SGD\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "# from net import Grokformer  # net - файл с реализацией трансформера\n",
        "from tqdm.notebook import tqdm\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm"
      ],
      "metadata": {
        "id": "k1crp9xxalsG"
      },
      "id": "k1crp9xxalsG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "#для четкой прорисовки графиков\n",
        "%config InlineBackend.figure_format = 'svg'"
      ],
      "metadata": {
        "id": "5e3JoQOlBMLW"
      },
      "id": "5e3JoQOlBMLW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6dbfd27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6dbfd27",
        "outputId": "389fe664-d6dc-4806-ac76-f1485b5d42fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b975976d",
      "metadata": {
        "id": "b975976d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import einops\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "id": "Rf31TZNjaVql"
      },
      "id": "Rf31TZNjaVql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8e52db5",
      "metadata": {
        "id": "f8e52db5"
      },
      "outputs": [],
      "source": [
        "# This code was taken directly from Neel Nanda's study of grokking:\n",
        "# https://colab.research.google.com/drive/1F6_1_cWXE5M7WocUcpQWp3v8z4b1jL20\n",
        "\n",
        "class HookPoint(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fwd_hooks = []\n",
        "        self.bwd_hooks = []\n",
        "\n",
        "    def give_name(self, name):\n",
        "        # Called by the model at initialisation\n",
        "        self.name = name\n",
        "\n",
        "    def add_hook(self, hook, dir='fwd'):\n",
        "        # Hook format is fn(activation, hook_name)\n",
        "        # Change it into PyTorch hook format (this includes input and output,\n",
        "        # which are the same for a HookPoint)\n",
        "        def full_hook(module, module_input, module_output):\n",
        "            return hook(module_output, name=self.name)\n",
        "        if dir=='fwd':\n",
        "            handle = self.register_forward_hook(full_hook)\n",
        "            self.fwd_hooks.append(handle)\n",
        "        elif dir=='bwd':\n",
        "            handle = self.register_backward_hook(full_hook)\n",
        "            self.bwd_hooks.append(handle)\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid direction {dir}\")\n",
        "\n",
        "    def remove_hooks(self, dir='fwd'):\n",
        "        if (dir=='fwd') or (dir=='both'):\n",
        "            for hook in self.fwd_hooks:\n",
        "                hook.remove()\n",
        "            self.fwd_hooks = []\n",
        "        if (dir=='bwd') or (dir=='both'):\n",
        "            for hook in self.bwd_hooks:\n",
        "                hook.remove()\n",
        "            self.bwd_hooks = []\n",
        "        if dir not in ['fwd', 'bwd', 'both']:\n",
        "            raise ValueError(f\"Invalid direction {dir}\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63f8102f",
      "metadata": {
        "id": "63f8102f"
      },
      "outputs": [],
      "source": [
        "# Embed & Unembed\n",
        "class Embed(nn.Module):\n",
        "    def __init__(self, d_vocab, d_model):\n",
        "        super().__init__()\n",
        "        self.W_E = nn.Parameter(torch.randn(d_model, d_vocab)/np.sqrt(d_model))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.einsum('dbp -> bpd', self.W_E[:, x])\n",
        "\n",
        "class Unembed(nn.Module):\n",
        "    def __init__(self, d_vocab, d_model):\n",
        "        super().__init__()\n",
        "        self.W_U = nn.Parameter(torch.randn(d_model, d_vocab)/np.sqrt(d_vocab))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return (x @ self.W_U)\n",
        "\n",
        "# Positional Embeddings\n",
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, max_ctx, d_model):\n",
        "        super().__init__()\n",
        "        self.W_pos = nn.Parameter(torch.randn(max_ctx, d_model)/np.sqrt(d_model))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x+self.W_pos[:x.shape[-2]]\n",
        "\n",
        "# LayerNorm\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, d_model, epsilon = 1e-4, model=[None]):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.w_ln = nn.Parameter(torch.ones(d_model))\n",
        "        self.b_ln = nn.Parameter(torch.zeros(d_model))\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.model[0].use_ln:\n",
        "            x = x - x.mean(axis=-1)[..., None]\n",
        "            x = x / (x.std(axis=-1)[..., None] + self.epsilon)\n",
        "            x = x * self.w_ln\n",
        "            x = x + self.b_ln\n",
        "            return x\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "# Attention\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_head, n_ctx, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.W_K = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
        "        self.W_Q = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
        "        self.W_V = nn.Parameter(torch.randn(num_heads, d_head, d_model)/np.sqrt(d_model))\n",
        "        self.W_O = nn.Parameter(torch.randn(d_model, d_head * num_heads)/np.sqrt(d_model))\n",
        "        self.register_buffer('mask', torch.tril(torch.ones((n_ctx, n_ctx))))\n",
        "        self.d_head = d_head\n",
        "        self.hook_k = HookPoint()\n",
        "        self.hook_q = HookPoint()\n",
        "        self.hook_v = HookPoint()\n",
        "        self.hook_z = HookPoint()\n",
        "        self.hook_attn = HookPoint()\n",
        "        self.hook_attn_pre = HookPoint()\n",
        "\n",
        "    def forward(self, x):\n",
        "        k = self.hook_k(torch.einsum('ihd,bpd->biph', self.W_K, x))\n",
        "        q = self.hook_q(torch.einsum('ihd,bpd->biph', self.W_Q, x))\n",
        "        v = self.hook_v(torch.einsum('ihd,bpd->biph', self.W_V, x))\n",
        "        attn_scores_pre = torch.einsum('biph,biqh->biqp', k, q)\n",
        "        attn_scores_masked = torch.tril(attn_scores_pre) - 1e10 * (1 - self.mask[:x.shape[-2], :x.shape[-2]])\n",
        "        attn_matrix = self.hook_attn(F.softmax(self.hook_attn_pre(attn_scores_masked/np.sqrt(self.d_head)), dim=-1))\n",
        "        z = self.hook_z(torch.einsum('biph,biqp->biqh', v, attn_matrix))\n",
        "        z_flat = einops.rearrange(z, 'b i q h -> b q (i h)')\n",
        "        out = torch.einsum('df,bqf->bqd', self.W_O, z_flat)\n",
        "        return out\n",
        "\n",
        "# MLP Layers\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, d_model, d_mlp, act_type, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.W_in = nn.Parameter(torch.randn(d_mlp, d_model)/np.sqrt(d_model))\n",
        "        self.b_in = nn.Parameter(torch.zeros(d_mlp))\n",
        "        self.W_out = nn.Parameter(torch.randn(d_model, d_mlp)/np.sqrt(d_model))\n",
        "        self.b_out = nn.Parameter(torch.zeros(d_model))\n",
        "        self.act_type = act_type\n",
        "        self.ln = LayerNorm(d_mlp, model=self.model)\n",
        "        self.hook_pre = HookPoint()\n",
        "        self.hook_post = HookPoint()\n",
        "        assert act_type in ['ReLU', 'GeLU']\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hook_pre(torch.einsum('md,bpd->bpm', self.W_in, x)) + self.b_in\n",
        "        x = self.ln(x)\n",
        "        if self.act_type=='ReLU':\n",
        "            x = F.relu(x)\n",
        "        elif self.act_type=='GeLU':\n",
        "            x = F.gelu(x)\n",
        "        x = self.hook_post(x)\n",
        "        x = torch.einsum('dm,bpm->bpd', self.W_out, x) + self.b_out\n",
        "        return x\n",
        "\n",
        "# Transformer Block\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, d_mlp, d_head, num_heads, n_ctx, act_type, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.ln1 = LayerNorm(d_model, model=self.model)\n",
        "        self.attn = Attention(d_model, num_heads, d_head, n_ctx, model=self.model)\n",
        "        self.ln2 = LayerNorm(d_model, model=self.model)\n",
        "        self.mlp = MLP(d_model, d_mlp, act_type, model=self.model)\n",
        "        self.hook_attn_out = HookPoint()\n",
        "        self.hook_mlp_out = HookPoint()\n",
        "        self.hook_resid_pre = HookPoint()\n",
        "        self.hook_resid_mid = HookPoint()\n",
        "        self.hook_resid_post = HookPoint()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hook_resid_mid(x + self.hook_attn_out(self.attn((self.hook_resid_pre(self.ln1(x))))))\n",
        "        x = self.hook_resid_post(x + self.hook_mlp_out(self.mlp(self.ln2(x))))\n",
        "        return x\n",
        "\n",
        "# Full transformer\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_layers, d_vocab, d_model, d_mlp, d_head, num_heads, n_ctx, act_type, use_cache=False, use_ln=True):\n",
        "        super().__init__()\n",
        "        self.cache = {}\n",
        "        self.use_cache = use_cache\n",
        "\n",
        "        self.embed = Embed(d_vocab, d_model)\n",
        "        self.pos_embed = PosEmbed(n_ctx, d_model)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(d_model, d_mlp, d_head, num_heads, n_ctx, act_type, model=[self]) for i in range(num_layers)])\n",
        "        self.ln = LayerNorm(d_model, model=[self])\n",
        "        self.unembed = Unembed(d_vocab, d_model)\n",
        "        self.use_ln = use_ln\n",
        "\n",
        "        for name, module in self.named_modules():\n",
        "            if type(module)==HookPoint:\n",
        "                module.give_name(name)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        x = self.pos_embed(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.ln(x)\n",
        "        x = self.unembed(x)\n",
        "        return x[:, -1]\n",
        "\n",
        "    def set_use_cache(self, use_cache):\n",
        "        self.use_cache = use_cache\n",
        "\n",
        "    def hook_points(self):\n",
        "        return [module for name, module in self.named_modules() if 'hook' in name]\n",
        "\n",
        "    def remove_all_hooks(self):\n",
        "        for hp in self.hook_points():\n",
        "            hp.remove_hooks('fwd')\n",
        "            hp.remove_hooks('bwd')\n",
        "\n",
        "    def cache_all(self, cache, incl_bwd=False):\n",
        "        # Caches all activations wrapped in a HookPoint\n",
        "        def save_hook(tensor, name):\n",
        "            cache[name] = tensor.detach()\n",
        "        def save_hook_back(tensor, name):\n",
        "            cache[name+'_grad'] = tensor[0].detach()\n",
        "        for hp in self.hook_points():\n",
        "            hp.add_hook(save_hook, 'fwd')\n",
        "            if incl_bwd:\n",
        "                hp.add_hook(save_hook_back, 'bwd')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5083af83",
      "metadata": {
        "id": "5083af83"
      },
      "source": [
        "### Функция генерации данных:\n",
        "p - деление по модулю p\n",
        "function - операция"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(14)\n",
        "torch.manual_seed(14)\n",
        "torch.cuda.manual_seed(14)"
      ],
      "metadata": {
        "id": "WHC5lkFnZPaS"
      },
      "id": "WHC5lkFnZPaS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3977773",
      "metadata": {
        "id": "c3977773"
      },
      "outputs": [],
      "source": [
        "def create_data_p(p: int, function):\n",
        "    x = torch.arange(p)  # 0..p\n",
        "    y = torch.arange(p)  # 0..p\n",
        "    x, y = torch.cartesian_prod(x, y).T  # декартово произведение x и y\n",
        "    result = function(x, y) % p\n",
        "    return torch.stack([x, y, result]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba42bfcc",
      "metadata": {
        "id": "ba42bfcc"
      },
      "outputs": [],
      "source": [
        "def prod(a, b):  # a*b\n",
        "    return a * b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summ(a, b):\n",
        "    return a + b"
      ],
      "metadata": {
        "id": "PyDIJ6vp_KTB"
      },
      "id": "PyDIJ6vp_KTB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e2b700d",
      "metadata": {
        "id": "7e2b700d"
      },
      "outputs": [],
      "source": [
        "def sinm(a, b):  # целая часть модуля синуса от a+b\n",
        "    return (abs(torch.sin(a+b))*sinp).to(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f3f087c",
      "metadata": {
        "id": "2f3f087c"
      },
      "outputs": [],
      "source": [
        "def nesim(a, b):  # несимметричная функция a*b+b*b\n",
        "    return (a*b+b*b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10e2ad91",
      "metadata": {
        "id": "10e2ad91"
      },
      "outputs": [],
      "source": [
        "p = 97\n",
        "device = torch.device(\"cuda:0\")  # \"cpu\" - процессор, \"cuda:0\" - видеокарта\n",
        "train_ratio = 0.4  # какая доля выборки уйдет на train\n",
        "batch_size = 512\n",
        "budget = 50000  # регулирует кол-во эпох\n",
        "sinp = 3*p  # множитель для функции синуса, чтобы результат был от 0 до sinp\n",
        "func = prod  # операция"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5095cc9d",
      "metadata": {
        "id": "5095cc9d"
      },
      "source": [
        "Авторы статьи в качестве входных параметров для трансформера использовали токены \"a\",\"o\",\"b\",\"=\",\"c\", но мы будем использовать только \"a\", \"b\", \"c\". Как нам кажется, токены \"o\" и \"=\" никакой ценности для нейросети не несут."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9476edc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9476edc5",
        "outputId": "5222e740-7a94-421c-bb09-9ed85659e682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  0,  0],\n",
            "        [ 0,  1,  0],\n",
            "        [ 0,  2,  0],\n",
            "        ...,\n",
            "        [96, 94,  3],\n",
            "        [96, 95,  2],\n",
            "        [96, 96,  1]])\n"
          ]
        }
      ],
      "source": [
        "# 1, 2, 3 столбец - \"a\", \"b\", \"c\" соответственно\n",
        "example = create_data_p(p, func)\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcb0bd49",
      "metadata": {
        "id": "dcb0bd49"
      },
      "source": [
        "Перемешиваем выборку и разбиваем на train и val:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d842e727",
      "metadata": {
        "id": "d842e727"
      },
      "outputs": [],
      "source": [
        "data = create_data_p(p, func)\n",
        "data = data.to(device)\n",
        "data_index = torch.randperm(data.shape[0], device=device)\n",
        "split = int(data.shape[0] * train_ratio)\n",
        "training_set = data[data_index[:split]]\n",
        "validation_set = data[data_index[split:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaa745ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaa745ff",
        "outputId": "6408aa8d-c261-4a70-f520-4f8463c2a529"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3763, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "training_set.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc13700c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc13700c",
        "outputId": "cb5b86a7-853a-46c3-f704-d0b1995faafe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0, 50,  0],\n",
              "        [78, 32, 71],\n",
              "        [63, 86, 83],\n",
              "        ...,\n",
              "        [72, 50, 11],\n",
              "        [24, 60, 82],\n",
              "        [54, 43, 91]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ],
      "source": [
        "validation_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61d9d0e1",
      "metadata": {
        "id": "61d9d0e1"
      },
      "outputs": [],
      "source": [
        "net = Transformer(num_layers=2,\n",
        "                    d_vocab=p,\n",
        "                    d_model=128,\n",
        "                    d_mlp=512,\n",
        "                    d_head=32,\n",
        "                    num_heads=4,\n",
        "                    n_ctx=3, # context length\n",
        "                    act_type='ReLU',\n",
        "                    use_cache=False,\n",
        "                    use_ln=True # use LayerNorm\n",
        "                 ).to(device)\n",
        "optimizer = SGD(net.parameters(), lr=1e-1, weight_decay=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e4e4ee0",
      "metadata": {
        "id": "0e4e4ee0"
      },
      "outputs": [],
      "source": [
        "# кол-во шагов оптимизации за 1 эпоху\n",
        "steps_per_epoch = math.ceil(training_set.shape[0] / batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e2a7496",
      "metadata": {
        "id": "0e2a7496"
      },
      "outputs": [],
      "source": [
        "def get_ravel_weights(model):\n",
        "    ww = []\n",
        "    for par in model.parameters():\n",
        "        ww.append(par.detach().cpu().data.numpy().ravel())\n",
        "    return np.concatenate(ww)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e81cb18",
      "metadata": {
        "id": "4e81cb18"
      },
      "outputs": [],
      "source": [
        "def isbatchnorm(module):\n",
        "    return issubclass(module.__class__, torch.nn.modules.batchnorm._BatchNorm)\n",
        "\n",
        "\n",
        "def _check_bn(module, flag):\n",
        "    if isbatchnorm(module):\n",
        "        flag[0] = True\n",
        "\n",
        "\n",
        "def check_bn(model):\n",
        "    flag = [False]\n",
        "    model.apply(lambda module: _check_bn(module, flag))\n",
        "    return flag[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bff8e5fe",
      "metadata": {
        "id": "bff8e5fe"
      },
      "source": [
        "## Connect 100 tr 0 val and 100 tr 100 val"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_norm(model):\n",
        "    return np.sqrt(sum(param.pow(2).sum().item() for param in model.parameters()))"
      ],
      "metadata": {
        "id": "5_QpQLPRmHNk"
      },
      "id": "5_QpQLPRmHNk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_si_norm(model):\n",
        "    return np.sqrt(sum(param.pow(2).sum().item() if param.requires_grad else 0. for param in model.parameters()))"
      ],
      "metadata": {
        "id": "3tYiDF_yg5k0"
      },
      "id": "3tYiDF_yg5k0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_grad_norm(model):\n",
        "    return np.sqrt(sum(param.grad.pow(2).sum().item() for param in model.parameters()))"
      ],
      "metadata": {
        "id": "RQP9Q2sFVdTp"
      },
      "id": "RQP9Q2sFVdTp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_norm_wot_last_layer(model):\n",
        "    return np.sqrt(sum(param.grad.pow(2).sum().item() if not param.grad is None else 0. for param in model.parameters()))"
      ],
      "metadata": {
        "id": "TI0yrk-oo021"
      },
      "id": "TI0yrk-oo021",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_norm_last_layer(model):\n",
        "    return np.sqrt(sum(param.pow(2).sum().item() if param.grad is None else 0. for param in model.parameters()))"
      ],
      "metadata": {
        "id": "_TPufUUqrig_"
      },
      "id": "_TPufUUqrig_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7287ce9c",
      "metadata": {
        "id": "7287ce9c"
      },
      "outputs": [],
      "source": [
        "train_acc, val_acc, train_loss, val_loss = [], [], [], []\n",
        "weights_norm, grad_norms = [], []\n",
        "norms = []\n",
        "effective_lr, effective_grad = [], []\n",
        "mean_effictive_grad = []\n",
        "mean_grad_norms = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad8de570",
      "metadata": {
        "id": "ad8de570"
      },
      "outputs": [],
      "source": [
        "k = 0\n",
        "for epoch in range(int(budget) // steps_per_epoch):\n",
        "    k += 1\n",
        "    # на каждой эпохе перемешиваем train\n",
        "    training_set = training_set[torch.randperm(training_set.shape[0]), :]\n",
        "\n",
        "    for data, is_train in [(training_set, True), (validation_set, False)]:\n",
        "\n",
        "        total_acc = 0\n",
        "        total_loss = 0\n",
        "        net.train(is_train)\n",
        "\n",
        "        dl = torch.split(data , batch_size, dim=0)  # делим на батчи\n",
        "        for input in dl:  # input - 1 батч\n",
        "            input = input.to(device)  # используем видеокарту\n",
        "            with torch.set_grad_enabled(is_train):\n",
        "                logits = net(input[:, :-1])  # предсказание\n",
        "                loss = cross_entropy(\n",
        "                    logits, input[:, -1].flatten().to(torch.long))\n",
        "                total_loss += loss.item() * input.shape[0]\n",
        "\n",
        "            if is_train:  # пересчитываем веса, вычисляя градиенты; обновляем lr\n",
        "                net.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                norm = calc_si_norm(net)\n",
        "                grad = calc_norm_wot_last_layer(net)\n",
        "                grad_norms.append(grad)\n",
        "                effective_grad.append(grad * norm)\n",
        "                weights_norm.append(norm)\n",
        "\n",
        "            acc = (logits.argmax(-1) == input[:, -1]).float().mean()\n",
        "            total_acc += acc.item() * input.shape[0]\n",
        "\n",
        "        if is_train:\n",
        "            train_acc.append(total_acc / training_set.shape[0])\n",
        "            train_loss.append(total_loss / training_set.shape[0])\n",
        "            norms.append(norm)\n",
        "\n",
        "        else:\n",
        "            val_acc.append(total_acc / validation_set.shape[0])\n",
        "            val_loss.append(total_loss / validation_set.shape[0])\n",
        "\n",
        "    effective_lr.append(optimizer.state_dict()['param_groups'][0]['lr'] / np.mean(weights_norm) ** 2)\n",
        "    mean_effictive_grad.append(np.mean(effective_grad))\n",
        "    mean_grad_norms.append(np.mean(grad_norms))\n",
        "\n",
        "    effective_grad = []\n",
        "    grad_norms = []\n",
        "    weights_norm = []\n",
        "\n",
        "    if train_acc[-1] == 1:\n",
        "        torch.save(net, 'net_train_100.pth')\n",
        "        break\n",
        "    print(f'Epoch {k}: Train / Val acc: {round(train_acc[-1], 4)} / {round(val_acc[-1], 4)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32f8e09",
      "metadata": {
        "id": "d32f8e09"
      },
      "outputs": [],
      "source": [
        "#for epoch in range(int(budget) // steps_per_epoch):\n",
        "while True:\n",
        "    k += 1\n",
        "    # на каждой эпохе перемешиваем train\n",
        "    training_set = training_set[torch.randperm(training_set.shape[0]), :]\n",
        "\n",
        "    for data, is_train in [(training_set, True), (validation_set, False)]:\n",
        "\n",
        "        total_acc = 0\n",
        "        total_loss = 0\n",
        "        net.train(is_train)\n",
        "\n",
        "        dl = torch.split(data , batch_size, dim=0)  # делим на батчи\n",
        "        for input in dl:  # input - 1 батч\n",
        "            input = input.to(device)  # используем видеокарту\n",
        "            with torch.set_grad_enabled(is_train):\n",
        "                logits = net(input[:, :-1])  # предсказание\n",
        "                loss = cross_entropy(\n",
        "                    logits, input[:, -1].flatten().to(torch.long))\n",
        "                total_loss += loss.item() * input.shape[0]\n",
        "\n",
        "            if is_train:  # пересчитываем веса, вычисляя градиенты; обновляем lr\n",
        "                net.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                norm = calc_si_norm(net)\n",
        "                grad = calc_norm_wot_last_layer(net)\n",
        "                grad_norms.append(grad)\n",
        "                effective_grad.append(grad * norm)\n",
        "                weights_norm.append(norm)\n",
        "\n",
        "            acc = (logits.argmax(-1) == input[:, -1]).float().mean()\n",
        "            total_acc += acc.item()*input.shape[0]\n",
        "\n",
        "        if is_train:\n",
        "            train_acc.append(total_acc / training_set.shape[0])\n",
        "            train_loss.append(total_loss / training_set.shape[0])\n",
        "            norms.append(norm)\n",
        "\n",
        "        else:\n",
        "            val_acc.append(total_acc / validation_set.shape[0])\n",
        "            val_loss.append(total_loss / validation_set.shape[0])\n",
        "\n",
        "    effective_lr.append(optimizer.state_dict()['param_groups'][0]['lr'] / np.mean(weights_norm) ** 2)\n",
        "    mean_effictive_grad.append(np.mean(effective_grad))\n",
        "    mean_grad_norms.append(np.mean(grad_norms))\n",
        "\n",
        "    effective_grad = []\n",
        "    grad_norms = []\n",
        "    weights_norm = []\n",
        "\n",
        "    if  val_acc[-1] == 1 or k == 20000:\n",
        "        torch.save(net, 'net_val_100.pth')\n",
        "        break\n",
        "    print(f'Epoch {k}: Train / Val acc: {round(train_acc[-1], 4)} / {round(val_acc[-1], 4)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc, label='train')\n",
        "plt.plot(val_acc, label='val', alpha=0.7)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('2L Transformer with SGDopt\\n  lr=1e-1, weight_decay=1e-3')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eC-9C3OPu0zH"
      },
      "id": "eC-9C3OPu0zH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('2L Transformer with SGDopt\\n  lr=1e-1, weight_decay=1e-3')\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(val_loss, label='val', alpha=0.7)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.grid()\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WhHd_QHM-fXF"
      },
      "id": "WhHd_QHM-fXF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(effective_lr, label='SGD: lr=1e-1, weight_decay=1e-3')\n",
        "plt.title('Effictive_lr')\n",
        "plt.xlabel('epoch')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "Xt8ybU6Wu4Ci"
      },
      "id": "Xt8ybU6Wu4Ci",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(mean_effictive_grad, label='SGD: lr=1e-1, weight_decay=1e-3')\n",
        "plt.title('Effective_grad')\n",
        "plt.xlabel('epoch')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "UHvQgKPEeJ7z"
      },
      "id": "UHvQgKPEeJ7z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(norms, label='SGD: lr=1e-1, weight_decay=1e-3')\n",
        "plt.title('weights_norm')\n",
        "plt.xlabel('epoch')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "JM6VCSrO0A78"
      },
      "id": "JM6VCSrO0A78",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}